---
title: "Activity 6 - Multinomial Logistic Regression"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


## Load Packages

```{r}
library(tidyverse)
library(dplyr)
library(tidymodels)
library(openintro)
library(ggplot2)
library(broom)
```

## The Data

Today we will analyze data from an online Ipsos (a consulting firm) survey that was conducted for a $\texttt{FiveThirthyEight}$ article [Why Many Americans Don't Vote](https://projects.fivethirtyeight.com/non-voters-poll-2020-election/).
You can read more about the survey design and respondents in the `README` of their [GitHub repo](https://github.com/fivethirtyeight/data/tree/master/non-voters) for the data.



Briefly, respondents were asked a variety of questions about their political beliefs, thoughts on multiple issues, and voting behavior.
We will focus on the demographic variables and the respondent's party identification to understand whether a person is a probable voter (with levels always, sporadic, rarely/never).

The specific variables we will use are (definitions are from the [`nonvoters_codebook.pdf`](https://github.com/fivethirtyeight/data/blob/master/non-voters/nonvoters_codebook.pdf)):

- `ppage`: Age of respondent
- `educ`: Highest educational attainment category
- `race`: Race of respondent, census categories
  Note: all categories except Hispanic are non-Hispanic
- `gender`: Gender of respondent
- `income_cat`: Household income category of respondent
- `Q30`: Response to the question "Generally speaking, do you think of yourself as a..."
  - 1: Republican
  - 2: Democrat
  - 3: Independent
  - 4: Another party, please specify
  - 5: No preference
  - -1: No response
- `voter_category`: past voting behavior:
  - **always**: respondent voted in all or all-but-one of the elections they were eligible in
  - **sporadic**: respondent voted in at least two, but fewer than all-but-one of the elections they were eligible in
  - **rarely/never**: respondent voted in 0 or 1 of the elections they were eligible in

These data can be read from the `data` folder in this Day 2 folder and were originally downloaded from: `https://github.com/fivethirtyeight/data/tree/master/non-voters`

**Notes**:

- Similarly to the data you used for the logistic regression portion of this activity, the researchers have the variable labeled `gender`, but it is unclear how this question was asked or what categorizations (if any) were provided to respondents to select from.
  We will use this as, "individuals that chose to provide their gender."
- The authors use weighting to make the final sample more representative on the US population for their article.
  We will **not** use weighting in this activity, so we will treat the sample as a convenience sample rather than a random sample of the population.

Now...

- Below, create a new R code chunk and write the code to:
  - Load `{tidyverse}` and `{tidymodels}` and any other packages you want to use.
  - *Read* in the *CSV* file from the `data` folder and store it in an R dataframe called `nonvoters`.
  - `select` only the variables listed above to want to make viewing/managing the data (and the `augment` output later) easier.
- Give your R code chunk a meaningful name, then run your code chunk or knit your document.
```{r}
# Load the required library
library(readr)

# Read the CSV file into a dataframe
non_voters <- read_csv("~/Documents/Summer 2024/R_Activities_Summer 2024/Week 2/activity06-logistic-regression/day02-multinomial/data/nonvoters.csv")
```

```{r}
# Basic exploration of variables
non_voters_subset <- non_voters[, c("ppage", "educ", "race", "gender", "income_cat", "Q30", "voter_category")]

# Display the first few rows of the subsetted dataframe
non_voters_subset
```

After doing this, answer the following questions:

1. Why do you think the authors chose to only include data from people who were eligible to vote for at least four election cycles?

Statistical Reliability: By focusing on individuals eligible to vote in at least four election cycles, the sample is more likely to include respondents who have a history of voting behavior across multiple elections. This provides a more robust dataset for analyzing patterns and attitudes towards voting and non-voting.

Longitudinal Perspective: Individuals who have been eligible to vote in multiple election cycles can provide insights into changes in voting behavior over time, as well as persistence or changes in factors influencing their decision to vote or not vote.

Policy Relevance: Understanding the behavior and attitudes of individuals who have consistently or sporadically voted across several elections can inform policies aimed at increasing voter turnout or addressing barriers to voting participation.

Comparative Analysis: It allows for comparisons between different groups of voters (e.g., always, sporadic, rarely/never) based on their voting histories, providing a richer understanding of the factors distinguishing these groups.

Avoiding Bias: Including only those eligible for multiple election cycles helps avoid biases that might arise from including individuals with limited voting experience or those who have become eligible recently, potentially skewing the analysis towards less informed or less engaged voters.

Overall, focusing on individuals eligible for at least four election cycles enhances the depth and reliability of the analysis concerning non-voters' demographics, attitudes, and behaviors in the context of U.S. elections.

2. In the FiveThirtyEight article, the authors include visualizations of the relationship between the [voter category and demographic variables](https://projects.fivethirtyeight.com/non-voters-poll-2020-election/images/NONVOTERS-1026-1.png?v=411f25ea).
  Select two of these demographic variables.
  Then, for each variable, create and interpret a plot to describe its relationship with `voter_category`.

1. Relationship between educ (Education Level) and voter_category
 a bar plot to visualize the distribution of voter categories (voter_category) across different education levels (educ).

Higher education levels (College graduate or more) tend to have a higher proportion of respondents categorized as always voters compared to lower education levels (Less than high school).
Conversely, respondents with lower education levels (Less than high school) tend to have a higher proportion of rarely/never voters compared to those with higher education levels. 

```{r}
# Bar plot of voter categories by education level
ggplot(non_voters_subset, aes(x = educ, fill = voter_category)) +
  geom_bar(position = "fill") +
  labs(x = "Education Level", y = "Proportion", fill = "Voter Category") +
  scale_fill_manual(values = c("always" = "green", "sporadic" = "blue", "rarely/never" = "red"),
                    labels = c("always" = "Always", "sporadic" = "Sporadic", "rarely/never" = "Rarely/Never")) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  ggtitle("Distribution of Voter Categories by Education Level")
```
2. Relationship between income_cat (Household Income Category) and voter_category

Higher income categories tend to have a higher proportion of respondents categorized as always voters compared to lower income categories.
Respondents in lower income categories ($0-$25k and $25k-$50k) tend to have a higher proportion of rarely/never voters compared to those in higher income categories ($100k+).


```{r}
# Bar plot of voter categories by income category
ggplot(non_voters_subset, aes(x = income_cat, fill = voter_category)) +
  geom_bar(position = "fill") +
  labs(x = "Income Category", y = "Proportion", fill = "Voter Category") +
  scale_fill_manual(values = c("always" = "green", "sporadic" = "blue", "rarely/never" = "red"),
                    labels = c("always" = "Always", "sporadic" = "Sporadic", "rarely/never" = "Rarely/Never")) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  ggtitle("Distribution of Voter Categories by Income Category")
```


We need to do some data preparation before we fit our multinomial logistic regression model.

- Create a new R code chunk and address these items:
  - The variable `Q30` contains the respondent’s political party identification.
    *Create a new variable* called `party` in the dataset that simplifies `Q30` into four categories: “Democrat”, “Republican”, “Independent”, “Other” (“Other” should also include respondents who did not answer the question).
  - The variable `voter_category` identifies the respondent’s past voter behavior.
    *Convert* this to a factor variable and ensure (*hint*: explore `relevel`) that the "rarely/never" level is the baseline level, followed by "sporadic", then "always".
- Then, run your code chunk or knit your document.

Step 1: Creating a New Variable party
We will create a new variable party based on the existing variable Q30 which contains the respondent's political party identification. The new party variable will simplify Q30 into four categories: "Democrat", "Republican", "Independent", and "Other" (which includes respondents who did not answer the question).

```{r}
nonvoters <- nonvoters %>% mutate(party = case_when(
  Q30 == '1' ~ 'Republican',
  Q30 == '2' ~ 'Democrat',
  Q30 == '3' ~ 'Independent',
    TRUE ~ 'Other'))
```

```{r relevel}
nonvoters <- nonvoters %>%
  mutate(voter_category = factor(voter_category, levels = c("rarely/never", "sporadic", "always")))

#nonvoters <- nonvoters %>%  mutate(Race = relevel(Race, ref = "Hispanic"))
nonvoters <- nonvoters %>%
  mutate(voter_category = fct_rev(voter_category))
```

```{r stacked Q30}
summary_df <- nonvoters %>%
  group_by(race, voter_category) %>%
  summarise(count = n()) %>% mutate(percent = count / sum(count) * 100)  # Calculate count percent

ggplot(summary_df, aes(x = percent, y = race, fill = voter_category)) +
  geom_bar(stat = "identity", position = "stack") +
  scale_fill_brewer(palette = "Set2")
```

Explanation
Creating party Variable: We used the recode() function from the dplyr package to recode values in Q30 into meaningful categories (Republican, Democrat, Independent, Other). This creates a new variable party which simplifies the original political party identification into a more manageable categorical variable.

Converting voter_category to Factor: We used the factor() function to convert voter_category into a factor variable. By specifying the levels argument, we ensure that the levels are ordered as "rarely/never" (baseline), "sporadic", and "always". This ordering is important for statistical analysis and interpretation where the baseline level (rarely/never) serves as a reference point.

These steps allow for clearer analysis and interpretation of political party identification (party) and past voter behavior (voter_category) in the dataset. Adjustments can be made based on specific requirements or additional data cleaning needs.


  Check that your changes are correct by creating a stacked bar graph using your new `Q30` variable as the $y$-axis and the `voter_category` represented with different colors.
  **Challenge**: Can you use the same color palette (*hint*: this is a handy tool, https://pickcoloronline.com/) that $\texttt{FiveThirthyEight}$ used in their article?
  
```{r}
# Stacked bar plot of voter categories by party affiliation
ggplot(non_voters_subset, aes(x = voter_category, fill = party)) +
  geom_bar(position = "stack") +
  labs(x = "Voter Category", y = "Count", fill = "Party") +
  scale_fill_manual(values = c("Republican" = "red", "Democrat" = "blue", 
                               "Independent" = "green", "Other" = "grey"),
                    labels = c("Republican", "Democrat", "Independent", "Other")) +
  ggtitle("Voter Categories by Party Affiliation") +
  theme_minimal()
```
  

## Fitting the model

Previously, we have explored logistic regression where the outcome/response/independent variable has two levels (e.g., "has feature" and "does not have feature").
We then used the logistic regression model

#$$
\begin{equation*}
\log\left(\frac{\hat{p}}{1-\hat{p}}\right) = \hat\beta_0 + \hat\beta_1x_1 + \hat\beta_2x_2 + \cdots + \hat\beta_px_p
\end{equation*}
#$$

Another way to think about this model is if we are interested in comparing our "has feature" category to the *baseline* "does not have feature" category.
If we let $y = 0$ represent the *baseline category*, such that $P(y_i = 1 | X's) = \hat{p}_i1$ and $P(y_i = 0 | X's) = 1 - \hat{p}_{i1} = \hat{p}_{i0}$, then the above equation can be rewritten as:

#$$
\begin{equation*}
\log\left(\frac{\hat{p}_{i1}}{\hat{p}_{i0}}\right) = \hat\beta_0 + \hat\beta_1x_{i1} + \hat\beta_2x_{i2} + \cdots + \hat\beta_px_{ip}
\end{equation*}
#$$

Recall that:

- The slopes ($\hat\beta_p$) represent when $x_p$ increases by one ($x_p$) unit, the odds of $y = 1$ compared to the baseline $y = 0$ are expected to multiply by a factor of $e^{\hat\beta_p}$.
-The intercept ($\hat\beta0$) respresents when all $x_j = 0$ (for $j = 1, \ldots, p$), the predicted odds of $y = 1$ versus the baseline $y = 0$ are $e^{\hat\beta_0}$.

For a multinomial (i.e., more than two categories, say, labeled $k = 1, 2, \ldots, K$) outcome variable, $P(y = 1) = p_1, P(y = 2) = p_2, \ldots, P(y = K) = p_k$, such that 

#$$
\begin{equation*}
\sum_{k = 1}^K p_k = 1
\end{equation*}
#$$

This is called the **multinomial distribution**.

For a multinomial logistic regression model it is helpful to identify a baseline category (say, $y = 1$).
We then fit a model such that $P(y = k) = p_k$ is a model of the $x$'s.

#$$
\begin{equation*}
\log\left(\frac{\hat{p}_{ik}}{\hat{p}_{i1}}\right) = \hat\beta_{0k} + \hat\beta_{1k}x_{i1} + \hat\beta_{2k}x_{i2} + \cdots + \hat\beta_{pk}x_{ip}
\end{equation*}
#$$

Notice that for a multinomial logistic model, we will have separate equations for each category of the outcome variable **relative to the baseline category**.
If the outcome has $K$ possible categories, there will be $K - 1$ equations as part of the multinomial logistic model.

Suppose we have an outcome variable $y$ with three possible levels coded as "A", "B", "C".
If "A" is the baseline category, then

#$$
\begin{equation*}
\begin{aligned}
\log\left(\frac{\hat{p}_{iB}}{\hat{p}_{iA}}\right) &= \hat\beta_{0B} + \hat\beta_{1B}x_{i1} + \hat\beta_{2B}x_{i2} + \cdots + \hat\beta_{pB}x_{ip} \\
\log\left(\frac{\hat{p}_{iC}}{\hat{p}_{iA}}\right) &= \hat\beta_{0C} + \hat\beta_{1C}x_{i1} + \hat\beta_{2C}x_{i2} + \cdots + \hat\beta_{pC}x_{ip} \\
\end{aligned}
\end{equation*}
#$$

```{r}
# Check the structure of `voter_category`
str(non_voters_subset$voter_category)
```

```{r}
# Convert `voter_category` to factor with specified levels
non_voters_subset$voter_category <- factor(non_voters_subset$voter_category,
                                           levels = c("rarely/never", "sporadic", "always"))
```


```{r}
# Define model specification
model_spec <- multinom_reg() %>%
  set_engine("nnet")

# Fit the model
model <- fit(model_spec, voter_category ~ ., data = non_voters_subset)
```


```{r}
library(tidymodels)
library(nnet)

# Convert voter_category to factor if not already done
non_voters_subset$voter_category <- factor(non_voters_subset$voter_category,
                                           levels = c("rarely/never", "sporadic", "always"))

# Define model specification
multi_mod <- multinom_reg() %>%
  set_engine("nnet")

# Fit the model
model <- fit(multi_mod, voter_category ~ ., data = non_voters_subset)
```

Now we will fit a model using age, race, gender, income, and education to predict voter category.
This is using `{tidymodels}`.

- In the code chunk below, replace "verbatim" with "r", 
- Provide the code chunk a meaningful name/title, then run it.
  
```{r}
# abbreviated recipe from previous activities
multi_mod <- multinom_reg() %>% 
  set_engine("nnet") %>% 
  fit(voter_category ~ ppage + educ + race + gender + income_cat, data = nonvoters)

tidy(multi_mod) %>% 
  print(n = Inf) # This will display all rows of the tibble
```

`{tidymodels}` is designed for cross-validation and so there needs to be some "trickery" when we build models using the entire dataset.
For example, when you type `multi_mod$fit$call` in your **Console**, you should see the following output:

```
> multi_mod$fit$call
nnet::multinom(formula = voter_category ~ ppage + educ + race + gender + income_cat, data = data, trace = FALSE)
```

The issue here is `data = data` and should be `data = nonvoters`.
To *repair* this, add the following to your previous R code chunk:

```
multi_mod <- repair_call(multi_mod, data = nonvoters)
```

Re-run your code chunk, then type `multi_mod$fit$call` in your **Console**, you should see the following output:

```
> multi_mod$fit$call
nnet::multinom(formula = voter_category ~ ppage + educ + race + gender + income_cat, data = nonvoters, trace = FALSE)
```

Yay!

Now, recall that the baseline category for the model is `"rarely/never"`.
Using your `tidy(multi_mod) %>% print(n = Inf)` output, complete the following items:

3. Write the model equation for the log-odds of a person that the "rarely/never" votes vs "always" votes.
  That is, finish this equation using your estimated parameters:

$$
\begin{equation*}
\log\left(\frac{\hat{p}_{\texttt{"always"}}}{\hat{p}_{\texttt{"rarely/never"}}}\right) = \cdots
\end{equation*}
$$

4. For your equation in (3), interpret the slope for `genderMale` in both log-odds and odds.


**Note**: The interpretation for the slope for `ppage` is a little more difficult to interpret.
However, we could mean-center age (i.e., subtract the mean age from each age value) to have a more meaningful interpretation.

## Predicting

We could use this model to calculate probabilities.
Generally, for categories $2, \ldots, K$, the probability that the $i^{th}$ observation is in the $k^{th}$ category is,

$$
\begin{equation*}
\hat{p}_{ik} = \frac{e^{\hat\beta_{0j} + \hat\beta_{1j}x_{i1} + \hat\beta_{2j}x_{i2} + \cdots + \hat\beta_{pj}x_{ip}}}{1 + \sum_{k = 2}^Ke^{\hat\beta_{0k} + \hat\beta_{1k}x_{1i} + \hat\beta_{2k}x_{2i} + \cdots + \hat\beta_{pk}x_{pi}}}
\end{equation*}
$$

And the baseline category, $k = 1$, 

$$
\begin{equation*}
\hat{p}_{i1} = 1 - \sum_{k = 2}^K \hat{p}_{ik}
\end{equation*}
$$

However, we will let R do these calculations.


- In the code chunk below, replace "verbatim" with "r", 
- Provide the code chunk a meaningful name/title, then run it.
  
```{r}
voter_aug <- augment(multi_mod, new_data = non_voters)

voter_aug

voter_aug %>% 
  select(contains("pred"))
```

Here we can see all of the predicted probabilities.
This is still rather difficult to view so a [confusion matrix](https://en.wikipedia.org/wiki/Confusion_matrix) can help us summarize how well the predictions fit the actual values.

- In the code chunk below, replace "verbatim" with "r", 
- Provide the code chunk a meaningful name/title, then run it.
  
```{r}
voter_conf_mat <- voter_aug %>% 
  count(voter_category, .pred_class, .drop = FALSE)

voter_conf_mat %>% 
  pivot_wider(
    names_from = .pred_class,
    values_from = n
  )
```

We can also visualize how well these predictions fit the original values.

- In the code chunk below, replace "verbatim" with "r", 
- Provide the code chunk a meaningful name/title, then run it.
  
```{r}
voters <- voter_conf_mat%>% 
  ggplot(aes(x = voter_category)) +
  geom_bar() +
  labs(
    main = "Self-reported voter category"
    )

voter_conf_mat %>% 
  ggplot(aes(x = voter_category, y = n, fill = .pred_class)) +
  geom_bar(stat = "identity") +
  labs(
    main = "Predicted vs self-reported voter category"
    )
```

Answer the following question:

5. What do you notice?

from the graph, there are more sporadic voters.

## Challenge: Explore with `party`

Fit the model that also includes `party` and discuss differences between the above model and this model with the additional predictor variable.
Can you assess (think back to the MLR activity for how we tested two models where one was a subset of another) the effect by including this additional predictor variable?

```{r}

```

