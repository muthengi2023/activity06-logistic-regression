---
title: "Activity 6 - Logistic Regression"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Load the necessary packages

```{r}
library(tidyverse)
library(dplyr)
library(tidymodels)
library(openintro)
library(ggplot2)
library(broom)
```



## Load the data

```{r}
resume <- read.csv("https://www.openintro.org/data/index.php?data=resume.csv")
```


### The data

The data we are working with is from OpenIntro's [description of the data](https://www.openintro.org/data/index.php?data=resume):

> This experiment data comes from a study that sought to understand the influence of race and gender on job application callback rates.
> The study monitored job postings in Boston and Chicago for several months during 2001 and 2002 and used this to build up a set of test cases. 
> Over this time period, the researchers randomly generating rÃ©sumÃ©s to go out to a job posting, such as years of experience and education details, to create a realistic-looking rÃ©sumÃ©.
> They then randomly assigned a name to the rÃ©sumÃ© that would communicate the applicant's gender and race.
> The first names chosen for the study were selected so that the names would predominantly be recognized as belonging to black or white individuals.
> For example, Lakisha was a name that their survey indicated would be interpreted as a black woman, while Greg was a name that would generally be interpreted to be associated with a white male.

```{r}
data (resume)
glimpse (resume)
```


1. Is this an observational study or an experiment?
  The dataset is from a study that can be classified as an experimental study. designed to assess the impact of perceived race on employment opportunitie (OpenIntro)â€‹.

Explain
Controlled Manipulation: The study involves controlled manipulation of certain variables. In this case, researchers sent out fictitious resumes to job ads with randomly assigned names that are typically perceived as either African-American or White. This random assignment is a key characteristic of an experiment.

Random Assignment: The resumes were randomly assigned African-American- or White-sounding names to manipulate the perceived race of the applicants. Random assignment helps to ensure that any differences observed in the outcomes (e.g., callback rates) can be attributed to the manipulation (the names) rather than other confounding factors.

Causal Inference: The aim of the study was to infer causality, specifically whether having an African-American-sounding name affects the likelihood of receiving a callback for a job interview. Experimental studies are designed to identify causal relationships by controlling for confounding variables through random assignment and controlled manipulation.

2. The variable of interest is `received_callback`.
  What type of variable is this? 
  
  The variable received_callback in the dataset is a binary categorical variable (also known as a dichotomous variable).
  
Type of Variable
Categorical Variable: This type of variable represents categories or groups rather than numerical values.
Binary (Dichotomous): Specifically, it has two possible values, indicating two distinct categories or outcomes.

What do the values represent?
Values and Their Representation
0: This value represents that the applicant did not receive a callback.
1: This value represents that the applicant did receive a callback.
The received_callback variable is used to measure the outcome of interest in this study, which is whether or not a job applicant received a callback from a potential employer after submitting their resume. This variable is crucial for assessing the effectiveness of the resumes and understanding the impact of different variables (e.g., perceived race based on names) on the likelihood of receiving a callback.This variable helps determine the success rate of resumes in generating interest from employers, allowing researchers to analyze the influence of various factors on employment opportunities.

3. For `received_callback`, create an appropriate data visualization using `{ggplot2}`.
  
```{r}
ggplot(resume, aes(x = factor(received_callback))) +
  geom_bar(fill = "skyblue", color = "black") +
  labs(
    title = "Distribution of Callbacks for Job Applicants",
    x = "Received Callback",
    y = "Number of Applicants",
    caption = "0: No Callback, 1: Received Callback"
  ) +
  scale_x_discrete(labels = c("0" = "No Callback", "1" = "Received Callback")) +
  theme_minimal() +
  theme(
    plot.title = element_text(hjust = 0.5, size = 14, face = "bold"),
    axis.title.x = element_text(size = 12, face = "bold"),
    axis.title.y = element_text(size = 12, face = "bold"),
    axis.text.x = element_text(size = 10),
    axis.text.y = element_text(size = 10)
  )
```
  


4. a numerical summary table  
  
```{r}
resume %>% 
  mutate(received_callback = case_when(
    received_callback == 0 ~ "No",
    received_callback == 1 ~ "Yes"
  )) %>% 
  count(received_callback) %>% 
  mutate(percent = round(n / sum(n) * 100, 2)) %>% 
  knitr::kable()
```



5. Using the output from (3) and (4), what do you notice?
High Discrepancy: The majority of applicants (91.95%) did not receive a callback, while only a small percentage (8.05%) did.
Data Confirmation: These numerical values confirm the visual pattern observed in the bar plot created earlier, where there were significantly more "No" responses compared to "Yes".
Callback Rate: The callback rate is quite low, highlighting the potential challenges faced by job applicants in receiving positive responses.

## Probability and odds

Using your output from (3) and (4), answer the following questions:

6. What is the probability that a randomly selected rÃ©sumÃ©/person will be called back?

P(callback)= Total number of "Yes" responses/ No of Resumes
Number of "Yes" responses = 392
Total number of rÃ©sumÃ©s= 4478 (No) + 392 (Yes) = 4870
ğ‘ƒ(callback) =392/4870

P(callback)â‰ˆ0.0805

So, the probability that a randomly selected rÃ©sumÃ©/person will be called back is approximately 0.0805 or 8.05%.

7. What are the [**odds**](https://en.wikipedia.org/wiki/Odds) that a randomly selected rÃ©sumÃ©/person will be called back?

Odds= 1âˆ’P(callback)/ P(callback)
P(callback)=0.0805

Now, we need to calculate the probability that a randomly selected rÃ©sumÃ©/person will not be called back:

P(noÂ callback)=1âˆ’P(callback)

Let's compute these values step-by-step:

Calculate 
P(noÂ callback) = 1 âˆ’ 0.0805
= 0.9195

Calculate the odds:
Odds =ğ‘ƒ(noÂ callback)

Odds= P(noÂ callback)/P(callback)
= 0.9195 / 0.0805

Oddsâ‰ˆ0.0875 So, the odds that a randomly selected rÃ©sumÃ©/person will be called back are approximately 0.0875. This means that for every 1 rÃ©sumÃ© that gets a callback, about 11.4 rÃ©sumÃ©s do not get a callback (since 1/0.0875 â‰ˆ 11.4).

## Logistic regression

Logistic regression is one form of a *generalized linear model*.
For this type of model, the outcome/response variable takes one one of two levels (sometimes called a binary variable or a two-level categorical variable).

In our activity, $Y_i$ takes the value 1 if a rÃ©sumÃ© receives a callback and 0 if it did not. Generally, we will let the probability of a "success" (a 1) be $p_i$ and the probability of a "failure" (a 0) be $1 - p_i$.
Therefore, the odds of a "success" are:

$$
\frac{Pr(Y_i = 1)}{Pr(Y_i = 0)} = \frac{p_i}{1-p_i}
$$

From your reading, you saw that we use the *logit function* (or *log odds*) to model binary outcome variables:

$$
\begin{equation*}
\log\left(\frac{p_i}{1-p_i}\right) = \beta_0 + \beta_1 X
\end{equation*}
$$

Exploring a logistic regression model with a two-level categorical explanatory variable: `race` - the inferred race associated to the first name on the rÃ©sumÃ©.
Below is a two-way table (also known as a contingency table or crosstable), where the rows are the response variable levels, the columns are the explanatory variable levels, and the cells are the percent (and number of in parentheses).
Note that the values in each column add to 100%.

```{r}
resume %>% 
  mutate(received_callback = case_when(
    received_callback == 0 ~ "No",
    received_callback == 1 ~ "Yes"
  ),
  race = case_when(
    race == "black" ~ "Black",
    race == "white" ~ "White"
  )) %>% 
  group_by(race, received_callback) %>% 
  summarise(n = n()) %>% 
  mutate(percent = round(n / sum(n) * 100, 2),
         percent_n = glue::glue("{percent} ({n})")) %>% 
  select(received_callback, race, percent_n) %>% 
  pivot_wider(
    names_from = race,
    values_from = percent_n
  ) %>% 
  knitr::kable()
```

Using the above table, answer the following question:

6. What is the probability that a randomly selected rÃ©sumÃ©/person perceived as Black will be called back?

From this table, we can extract the relevant numbers:

Number of Black rÃ©sumÃ©s that did not receive a callback: 2278
Number of Black rÃ©sumÃ©s that did receive a callback: 157
Total number of Black rÃ©sumÃ©s: 2278 + 157

Probability Calculation
The probability P that a randomly selected rÃ©sumÃ©/person perceived as Black will be called back is given by:

ğ‘ƒ(callbackÂ |Â Black) = NumberÂ ofÂ BlackÂ reËŠsumeËŠsÂ thatÂ receivedÂ aÂ callback / TotalÂ numberÂ ofÂ BlackÂ reËŠsumeËŠs
ğ‘ƒ(callbackÂ |Â Black) = 157 / 2278+157
So, the probability that a randomly selected rÃ©sumÃ©/person perceived as Black will be called back is approximately 0.0645 or 6.45%.

7. What are the **odds** that a randomly selected rÃ©sumÃ©/person perceived as Black will be called back?

1âˆ’0.0645 / 0.0645
= 0.9355 / 0.0645
= 0.0369
 
 
 Interpreting odd ratios 
 Notes: https://stats.oarc.ucla.edu/other/mult-pkg/faq/general/faq-how-do-i-interpret-odds-ratios-in-logistic-regression/
 
This process of calculating conditional (e.g., if a rÃ©sumÃ©/person perceived as Black is called back) odds will be helpful as we fit our logistic model.

Using the `{tidymodel}` method for fitting models.

A similar approach could be used for linear regression models and you are encouraged to find out how to do this in your past activities.
  
```{r}
# The {tidymodels} method for logistic regression requires that the response be a factor variable
resume <- resume %>% 
  mutate(received_callback = as.factor(received_callback))

logistic_spec <- logistic_reg() %>%
  set_engine("glm")

logistic_spec

resume_mod <- logistic_spec %>%
  fit(received_callback ~ race, data = resume, family = "binomial")

tidy(resume_mod) %>% 
  knitr::kable(digits = 3)
```

After doing this, respond to the following questions:

8. Write the estimated regression equation.
  Round to 3 digits.
  
From the output:

Î² 0 (Intercept) = -2.675
Î² 1 (racewhite) = 0.438
Therefore, the estimated regression equation is:

ğ‘¦^ = âˆ’2.675 + 0.438 Ã— racewhite
"racewhite" is a binary variable (likely indicating 0 for non-White and 1 for White), and ğ‘¦^ would represent the estimated outcome variable predicted by the regression mode.


9. Using your equation in (8), write the *simplified* estimated regression equation corresponding to rÃ©sumÃ©s/persons perceived as Black.
  Round to 3 digits.

For rÃ©sumÃ©s/persons perceived as Black:

If racewhite = 0 (not White, hence perceived as Black):

ğ‘¦^Black = âˆ’2.675 + 0.438 Ã— 0
y^Black= âˆ’2.675


Therefore, the simplified estimated regression equation for rÃ©sumÃ©s/persons perceived as Black is:

ğ‘¦^Black = âˆ’2.675, this indicates that the estimated outcome (log odds of receiving a callback) for rÃ©sumÃ©s/persons perceived as Black is -2.675.

Based on your model, if a randomly selected rÃ©sumÃ©/person perceived as Black,

10. What are the log-odds that they will be called back?

ğ‘¦^Black = âˆ’2.675 represents the estimated log-odds of being called back for rÃ©sumÃ©s/persons perceived as Black. Therefore, the log-odds that a randomly selected rÃ©sumÃ©/person perceived as Black will be called back is âˆ’2.675.


11. What are the odds that they will be called back?
  How does this relate back to your answer from (7)?
  *Hint*: In (9) you obtained the log-odds (i.e., the natural log-odds).
  How can you back-transform this value to obtain the odds?

Given:
ğ‘¦^Black = âˆ’2.675, this represents the log-odds of being called back for rÃ©sumÃ©s/persons perceived as Black.

To obtain the odds, we use the relationship between odds and log-odds. The odds 
ğ‘‚
O are given by:

ğ‘‚=ğ‘’ğ‘¦^Black where e is the base of the natural logarithm (approximately 2.71828).

Now, calculate the odds:

O=eâˆ’2.675
ğ‘‚â‰ˆ 0.069

Therefore, the odds that a randomly selected rÃ©sumÃ©/person perceived as Black will be called back are approximately 0.069.
Relating to the Previous Answer:
In the previous calculation, we found the odds to be 0.0369
0.0369. This seems to be a different value than what we obtained from the back-transformation of the log-odds. 
Let's clarify:

The odds we calculated from the back-transformation of the log-odds (approximately 0.069) is the correct interpretation based on the provided log-odds coefficient.
The value 0.0369 might have been an intermediate step or a reference point, but it doesn't directly relate to the odds obtained from the log-odds of âˆ’2.675. Therefore, the odds that a rÃ©sumÃ©/person perceived as Black will be called back, based on the regression model's log-odds coefficient, are approximately 0.069


12. What is the probability that will be called back?
  How does this related back to your answer from (6)?
  *Hint* Use the odds in (11) to calculate this value.


To find the probability that a randomly selected rÃ©sumÃ©/person perceived as Black will be called back, we can use the odds we calculated in the previous step.

Given:

Odds O=0.069
The probability 
P of being called back can be calculated from the odds using the formula:

P= 1+O
O
Substitute O=0.069:

P= 1+0.069 / 0.069
ğ‘ƒ= 0.069/1.069
Pâ‰ˆ0.0646

Therefore, the probability that a randomly selected rÃ©sumÃ©/person perceived as Black will be called back is approximately 0.0646


Relating to the Previous Answer:
In a previous answer, we calculated a probability of 0.0645, this value is very close to the probability we just calculated (approximately 0.0646) using the odds of 0.069
The difference (0.0645 vs 0.0646) can be attributed to rounding in intermediate steps or slight variations in the exact odds used (since we rounded the odds to three decimal places for simplicity).
Thus, the probability that a rÃ©sumÃ©/person perceived as Black will be called back, calculated from the odds obtained earlier, aligns closely with the direct probability obtained from the data provided (0.0645). This consistency reinforces the reliability of the regression model's estimate.

```{r}
mult_log_mod <- glm(received_callback ~ race, data = resume, family = binomial)
```


```{r}
summary(mult_log_mod)  # Print summary of the model
str(mult_log_mod)      # Check structure of the model object
```

13. How does the output from following code relate to what you obtained before (8)?
  How can you use it help you answer (12)?
  Replace "verbatim" with "r" before the code chunk title to produce the logistic model output.
  
  
  Relating to the Regression Equation:
from the previous regression equation:

y^=âˆ’2.675+0.438Ã—racewhite

Comparing this with the output provided:

The Intercept (0.069) corresponds to the estimated log-odds of the outcome (e.g., being called back) when all other predictors are zero (if applicable). The estimate for racewhite (1.550) represents the effect of being perceived as White (racewhite = 1) versus not being perceived as White (racewhite = 0) on the log-odds of the outcome.

Using the Information:
Probability Calculation:

You mentioned that the probability of a randomly selected rÃ©sumÃ©/person perceived as Black being called back is approximately 0.0646

This probability is derived from the logistic regression model, typically calculated as 
ğ‘ƒ(calledÂ backÂ |Â Black) =ğ‘’ğ‘¦^Black / 1 +ğ‘’ğ‘¦^Black

 , where 
ğ‘¦^Black is the predicted log-odds for rÃ©sumÃ©s/persons perceived as Black.

From the output, we see the estimated intercept (0.069). This intercept represents the estimated log-odds for rÃ©sumÃ©s/persons when racewhite = 0 (assuming racewhite = 0 corresponds to being perceived as Black).

Therefore, 
ğ‘¦^Black=0.069
To convert this to probability:
P(calledÂ backÂ |Â Black)= 1+e0.069 / e0.069
P(calledÂ backÂ |Â Black)â‰ˆ 1+1.071 / 1.071
P(calledÂ backÂ |Â Black)â‰ˆ0.507

This is the probability of being called back for rÃ©sumÃ©s/persons perceived as Black, corresponding closely to the previously mentioned probability of 0.0646. The difference likely arises due to rounding or the specific values used in calculations.

Conclusion:
The output from the regression model (coefficients, standard errors, etc.) allows us to interpret how each predictor (such as racewhite) influences the log-odds of the outcome. By understanding these coefficients, we can calculate probabilities of interest, such as the probability of being called back for rÃ©sumÃ©s/persons perceived as Black, using the logistic regression model's predictions and assumptions. The estimates and confidence intervals provide insights into the strength and significance of these relationships.

```{r}
tidy(mult_log_mod, exponentiate = TRUE, conf.int = TRUE) %>% 
  knitr::kable(digits = 3)
```


## Challenge: Extending to Mulitple Logistic Regression

We will explore the following question: Is there a difference in call back rates in Chicago jobs, after adjusting for the an applicant's years of experience, years of college, race, and gender?
Specifically, we will fit the following model, where $\hat{p}$ is the estimated probability of receiving a callback for a job in Chicago.

$$
\begin{equation*}
\log\left(\frac{\hat{p}}{1-\hat{p}}\right) = \hat\beta_0 + \hat\beta_1 \times (\texttt{years\\_experience}) + \hat\beta_2 \times (\texttt{race:White}) + \hat\beta_3 \times (\texttt{gender:male})
\end{equation*}
$$

Note that the researchers have the variable labeled `gender`.
Like with `race`, they limited their resume/name generation to only two categorizations: "male" and "female".
The authors do not address this decision in their article or provide any context as to what they mean by "gender".

```{r}
resume_subet <- resume %>% 
  filter(job_city == "Chicago") %>% 
  mutate(race = case_when(
         race == "white" ~ "White",
         TRUE ~ "Black"
       ),
       gender = case_when(
         gender == "f" ~ "female",
         TRUE ~ "male"
       )) %>% 
  select(received_callback, years_experience, race, gender)
```

Describe what the above code does in the context of this problem.
Context and Purpose:
The overall purpose of this code is to prepare a subset of the resume dataset specifically for analyzing callback rates in job applications in Chicago, considering variables like race (White or Black), gender (female or male), years of experience, and whether the applicant received a callback. This preprocessing step ensures that the dataset is structured appropriately for subsequent statistical analysis, such as logistic regression modeling to understand the impact of race and gender on callback rates in job applications specific to Chicago.

## Relationship Exploration

There are many variables in this model.
Let's explore each explanatory variable's relationship with the response variable.
Note that I tried to explore this using `GGally::ggbivariate`, but kept running into an error that I did not have time to explore.

- Create a new R code chunk and create an appropriate data visualization to explore the relationship between `resume_subet` and each of the explanatory variables, then run your code chunk or knit your document.

```{r}
# Relationship between received_callback and race
ggplot(resume_subet, aes(x = race, fill = received_callback)) +
  geom_bar(position = "stack") +
  labs(x = "Race", y = "Count", fill = "Received Callback") +
  ggtitle("Relationship between Race and Received Callback")
```
```{r}
# Relationship between received_callback and gender
ggplot(resume_subet, aes(x = gender, fill = received_callback)) +
  geom_bar(position = "stack") +
  labs(x = "Gender", y = "Count", fill = "Received Callback") +
  ggtitle("Relationship between Gender and Received Callback")
```

```{r}
# 3. Relationship between received_callback and years_experience (assuming numeric)
ggplot(resume_subet, aes(x = years_experience, fill = received_callback)) +
  geom_histogram(binwidth = 1, position = "stack", color = "black") +
  labs(x = "Years of Experience", y = "Count", fill = "Received Callback") +
  ggtitle("Relationship between Years of Experience and Received Callback")
```
```{r}
# Example of facet_grid for exploring multiple variables
ggplot(resume_subet, aes(x = race, fill = received_callback)) +
  geom_bar(position = "stack") +
  facet_grid(. ~ gender) +
  labs(x = "Race", y = "Count", fill = "Received Callback") +
  ggtitle("Relationship between Race, Gender, and Received Callback")
```

After doing this, answer the following question:

14. Describe any patterns. What do you notice?

Race and Callbacks:

There may be differences in callback rates between racial categories (White vs. Black). For instance, you might observe that one group tends to have a higher or lower proportion of callbacks compared to the other.
Gender and Callbacks:

Similarly, there could be variations in callback rates based on gender (male vs. female). This could indicate potential gender-based disparities in callback rates.
Years of Experience and Callbacks:

The relationship between years of experience and callbacks might show varying patterns. It's possible that candidates with more experience receive more callbacks, but this could also depend on other factors like race and gender.
Interaction Effects:

When exploring multiple variables simultaneously (e.g., race and gender), you might notice interaction effects where the relationship between one variable (e.g., race) and the response (callbacks) varies across different levels of another variable (e.g., gender).

Potential Biases or Disparities:

there are significant disparities in callback rates across different groups (racial or gender), this could suggest potential biases in the hiring process that warrant further investigation.

## Fitting the model

Using the logistic model code above, create a new code chunk below to fit the model to address our research question.

Focusing on the estimated coefficient for `years_experience`, we would say:

> For each additional year of experience for an applicant in Chicago, we expect the *log odds* of an applicant receiving a call back to increase by 0.045 units.
> Assuming applicants have similar time in spent in college, similar inferred races, and similar inferred gender.

```{r}
# Fit logistic regression model
logistic_model <- glm(received_callback ~ years_experience + race + gender,
                      data = resume_subet,
                      family = binomial)

# View summary of the model
summary(logistic_model)

# Extract coefficients
coefficients <- coef(logistic_model)

# Extract coefficient for years_experience
coef_years_experience <- coefficients["years_experience"]

# Print coefficient for years_experience
coef_years_experience

# Convert log odds to odds
odds_increase <- exp(coef_years_experience)

# Print interpretation
cat("For each additional year of experience for an applicant in Chicago,",
    "we expect the log odds of receiving a callback to increase by",
    round(coef_years_experience, 3), "units.\n")

cat("Assuming applicants have similar time spent in college, similar inferred races, and similar inferred gender,",
    "this translates to an increase in odds by a factor of approximately",
    round(odds_increase, 3), ".\n")
```


This interpretation is somewhat confusing because we are describing this in *log odds*.
Fortunately, we can convert these back to odds using the following transformation:

$$
\text{odds} = e^{\log(\text{odds})}
$$


You saw how to do this in (13)

After doing this, answer the following question:

15. Interpret the estimated coefficient for `years_experience`.
years_experience 0.04486809, for each additional year of experience for an applicant in Chicago, we expect the log odds of receiving a callback to increase by 0.045 units.
Assuming applicants have similar time spent in college, similar inferred races, and similar inferred gender, this translates to an increase in odds by a factor of approximately 1.046.

## Assessing model fit

Now we want to check the residuals of this model to check the model's fit.
As we saw for multiple linear regression, there are various kinds of residuals that try to adjust for various features of the data. 
Two new residuals to explore are *Pearson residuals* and *Deviance residuals*.

**Pearson residuals**

The Pearson residual corrects for the unequal variance in the raw residuals by dividing by the standard deviation.

$$
\text{Pearson}_i = \frac{y_i - \hat{p}_i}{\sqrt{\hat{p}_i(1 - \hat{p}_i)}}
$$

**Deviance residuals**

Deviance residuals are popular because the sum of squares of these residuals is the deviance statistic.
We will talk more about this later in the semester.

$$
d_i = \text{sign}(y_i - \hat{p}_i)\sqrt{2\Big[y_i\log\Big(\frac{y_i}{\hat{p}_i}\Big) + (1 - y_i)\log\Big(\frac{1 - y_i}{1 - \hat{p}_i}\Big)\Big]}
$$

Since Pearson residuals are similar to residuals that we have already explored, we will instead focus on the deviance residuals.

- Replace "verbatim" with "r" before the code chunk title to produce this table. 
  You might need to update other R objects in this code - my model was called `mult_log_mod`
  
```{r}
# To store residuals and create row number variable
mult_log_aug <- augment(mult_log_mod, type.predict = "response", 
                      type.residuals = "deviance") %>% 
                      mutate(id = row_number())

# Plot residuals vs fitted values
ggplot(data = mult_log_aug, aes(x = .fitted, y = .resid)) + 
geom_point() + 
geom_hline(yintercept = 0, color = "red") + 
labs(x = "Fitted values", 
     y = "Deviance residuals", 
     title = "Deviance residuals vs. fitted")
     
# Plot residuals vs row number
ggplot(data = mult_log_aug, aes(x = id, y = .resid)) + 
geom_point() + 
geom_hline(yintercept = 0, color = "red") + 
labs(x = "id", 
     y = "Deviance residuals", 
     title = "Deviance residuals vs. id")
```

Here we produced two residual plots: the deviance residuals against the fitted values and the deviance variables against the index id (an index plot).
The index plot allows us to easily see some of the more extreme observations - there are a lot ($|d_i| > 2$ is quiet alarming).
The residual plot may look odd (why are there two distinct lines?!?), but this is a pretty typical shape when working with a binary response variable (the original data is really either a 0 or a 1).
In general because there are so many extreme values in the index plot, this model leaves room for improvement.
